{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5_CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "tJj2C9z4-3UY"
      },
      "cell_type": "markdown",
      "source": [
        "# STAT202A HW5 --- Convolutional Networks\n",
        "So far we have worked with fully-connected networks, using them to explore different optimization strategies and network architectures. Fully-connected networks are a good testbed for experimentation because they are very computationally efficient, but in practice all state-of-the-art results use convolutional networks instead.\n",
        "\n",
        "In this homework, your are required to implement convolution layer, forward and backward. All other part of the code are given. You will then use these layers to train a convolutional network on the CIFAR-10 dataset.\n",
        "\n",
        "Please following these steps,\n",
        "\n",
        "- STEP 1: Implement two function in second block, CNN forward and backward.\n",
        "- STEP 2: Read the code I provided, especially code in this pythonbook, the definition of CNN network in second block class. Add comments to codes in second blocks. (You can also read code provided in zip, but you do not need to make comment)\n",
        "- STEP 3: Run each block one by one see every thing works well.\n",
        "- STEP 4: Try to turn the learning rate and other setting to make final cifar learning well. Notice the cifar training use fast version CNN so this is not affected by your implementation. i.e. even you you fail to implement CNN layer, you can still it play it.\n",
        "- STEP 5: Doing more extra play at the end of this pythonbook. e.g. : Try to virtualize more filter / try to plot an accuracy according to different setting / calculate the accuracy by each class ... It is extra and optional.\n",
        "- STEP 6: Press Ctrl + P (or Commend + P) to print this page to pdf. Then download this ipynb files. \n",
        "- STEP 7: Submit the pdf and ipynb files only to ccle. (Two files, pdf and ipynb, no other filetype accepted)\n",
        "\n",
        "In order to useit in  google Colab, **remember to change Runtime -> change runtime type -> python version from python 3 to python 2**. Then run the first block, select the zip files I provided to upload and this block of code will automaticlly unzip it. Then, it will download cifar files and makefiles. \n",
        "\n",
        "If any problem caused later and crack the runtime. Remember to reset the runtime by Runtime -> Reset all runtimes and rerun the first block."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LqQffH-R_0VL",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1024
        },
        "outputId": "a949da9e-2a55-42fa-fcc5-82c3b6eab3e9"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!unzip HW5_code\n",
        "!pip install Cython==0.21\n",
        "!python HW5_code/setup.py build_ext --inplace\n",
        "!mv im2col_cython.c HW5_code/im2col_cython.c\n",
        "!mv im2col_cython.so HW5_code/im2col_cython.so\n",
        "!mv im2col_cython.pyx HW5_code/im2col_cython.pyx\n",
        "!wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "!tar -xzvf cifar-10-python.tar.gz\n",
        "!rm cifar-10-python.tar.gz "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7efbe033-8af0-4e4b-a284-1dfd0598b1f3\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7efbe033-8af0-4e4b-a284-1dfd0598b1f3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving HW5_code (2).zip to HW5_code (2).zip\n",
            "Archive:  HW5_code.zip\n",
            "replace HW5_code/data_utils.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: HW5_code/data_utils.py  \n",
            "replace HW5_code/fast_layers.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: HW5_code/fast_layers.py  \n",
            "  inflating: HW5_code/gradient_check.py  \n",
            "  inflating: HW5_code/im2col.py      \n",
            "  inflating: HW5_code/layers.py      \n",
            "  inflating: HW5_code/layer_utils.py  \n",
            "  inflating: HW5_code/optim.py       \n",
            "  inflating: HW5_code/setup.py       \n",
            "  inflating: HW5_code/solver.py      \n",
            "  inflating: HW5_code/vis_utils.py   \n",
            " extracting: HW5_code/__init__.py    \n",
            "  inflating: im2col_cython.pyx       \n",
            "Requirement already satisfied: Cython==0.21 in /usr/local/lib/python2.7/dist-packages (0.21)\n",
            "Compiling im2col_cython.pyx because it changed.\n",
            "Cythonizing im2col_cython.pyx\n",
            "running build_ext\n",
            "building 'im2col_cython' extension\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-nbjU53/python2.7-2.7.15~rc1=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I/usr/include/python2.7 -c im2col_cython.c -o build/temp.linux-x86_64-2.7/im2col_cython.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1816:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:18\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kim2col_cython.c:232\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it by \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:27:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kim2col_cython.c:232\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/__multiarray_api.h:1463:1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K_import_array\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " \u001b[01;35m\u001b[K_import_array\u001b[m\u001b[K(void)\n",
            " \u001b[01;35m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-nbjU53/python2.7-2.7.15~rc1=. -fstack-protector-strong -Wformat -Werror=format-security -Wl,-Bsymbolic-functions -Wl,-z,relro -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-nbjU53/python2.7-2.7.15~rc1=. -fstack-protector-strong -Wformat -Werror=format-security build/temp.linux-x86_64-2.7/im2col_cython.o -o /content/im2col_cython.so\n",
            "--2018-11-12 06:07:41--  http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  26.6MB/s    in 6.8s    \n",
            "\n",
            "2018-11-12 06:07:48 (23.9 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6C9ZWqH0CE5T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2f11f716-c7b9-4e54-8256-b1fe72b968cc"
      },
      "cell_type": "code",
      "source": [
        "# As usual, a bit of setup\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from HW5_code.data_utils import get_CIFAR10_data\n",
        "from HW5_code.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
        "from HW5_code.layers import *\n",
        "from HW5_code.fast_layers import *\n",
        "from HW5_code.solver import Solver\n",
        "from HW5_code.layer_utils import *\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading external modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "def rel_error(x, y):\n",
        "  \"\"\" returns relative error \"\"\"\n",
        "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
        "\n",
        "class ThreeLayerConvNet(object):\n",
        "    \"\"\"\n",
        "    A three-layer convolutional network with the following architecture:\n",
        "    conv - relu - 2x2 max pool - fc - relu - fc - softmax\n",
        "    The network operates on minibatches of data that have shape (N, C, H, W)\n",
        "    consisting of N images, each with height H and width W and with C input\n",
        "    channels.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=(3, 32, 32), num_filters=32, filter_size=7,\n",
        "                 hidden_dim=100, num_classes=10, weight_scale=1e-3, reg=0.0,\n",
        "                 dtype=np.float32):\n",
        "        \"\"\"\n",
        "        Initialize a new network.\n",
        "        Inputs:\n",
        "        - input_dim: Tuple (C, H, W) giving size of input data\n",
        "        - num_filters: Number of filters to use in the convolutional layer\n",
        "        - filter_size: Size of filters to use in the convolutional layer\n",
        "        - hidden_dim: Number of units to use in the fully-connected hidden layer\n",
        "        - num_classes: Number of scores to produce from the final fc layer.\n",
        "        - weight_scale: Scalar giving standard deviation for random initialization\n",
        "          of weights.\n",
        "        - reg: Scalar giving L2 regularization strength\n",
        "        - dtype: numpy datatype to use for computation.\n",
        "        \"\"\"\n",
        "        self.params = {}\n",
        "        self.reg = reg\n",
        "        self.dtype = dtype\n",
        "        \n",
        "        C, H, W = input_dim\n",
        "        self.params['W1'] = np.random.normal(0, weight_scale, [num_filters, 3, filter_size, filter_size])\n",
        "        self.params['b1'] = np.zeros([num_filters])\n",
        "        self.params['W2'] = np.random.normal(0, weight_scale, [np.int(H/2)*np.int(H/2)*num_filters, hidden_dim])\n",
        "        self.params['b2'] = np.zeros([hidden_dim])\n",
        "        self.params['W3'] = np.random.normal(0, weight_scale, [hidden_dim, num_classes])\n",
        "        self.params['b3'] = np.zeros([num_classes])\n",
        "\n",
        "        for k, v in self.params.items():\n",
        "            self.params[k] = v.astype(dtype)\n",
        "\n",
        "\n",
        "    def loss(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Evaluate loss and gradient for the three-layer convolutional network.\n",
        "        Input / output: Same API as TwoLayerNet in fc_net.py.\n",
        "        \"\"\"\n",
        "        W1, b1 = self.params['W1'], self.params['b1']\n",
        "        W2, b2 = self.params['W2'], self.params['b2']\n",
        "        W3, b3 = self.params['W3'], self.params['b3']\n",
        "\n",
        "        # pass conv_param to the forward pass for the convolutional layer\n",
        "        filter_size = W1.shape[2]\n",
        "        \n",
        "        # stride: step size that filter scans over image\n",
        "        # pad: add additional zeros out of the image to match the input and output size\n",
        "        conv_param = {'stride': 1, 'pad': (filter_size - 1) // 2}\n",
        "\n",
        "        # pass pool_param to the forward pass for the max-pooling layer\n",
        "        pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
        "\n",
        "        scores = None\n",
        "        \n",
        "        # forward pass\n",
        "        layer1_out, combined_cache = conv_relu_pool_forward(X, W1, b1,  conv_param, pool_param)\n",
        "        fc1_out, fc1_cache = fc_forward(layer1_out, W2, b2)\n",
        "        relu2_out, relu2_cache = relu_forward(fc1_out)\n",
        "        fc2_out, fc2_cache = fc_forward(relu2_out, W3, b3)\n",
        "\n",
        "        scores = np.copy(fc2_out)\n",
        "        if y is None:\n",
        "            return scores\n",
        "\n",
        "        loss, grads = 0, {}\n",
        "        \n",
        "        loss, dsoft = softmax_loss(scores, y)\n",
        "        loss += self.reg*0.5*(np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3)))\n",
        "        \n",
        "        \n",
        "        # backward pass\n",
        "        dx3, dw3, db3 = fc_backward(dsoft, fc2_cache)\n",
        "        drelu2 = relu_backward(dx3, relu2_cache)\n",
        "        dx2, dw2, db2 = fc_backward(drelu2, fc1_cache)\n",
        "        dx1, dw1, db1 = conv_relu_pool_backward(dx2, combined_cache)\n",
        "\n",
        "        grads['W3'], grads['b3'] = dw3 + self.reg*W3, db3\n",
        "        grads['W2'], grads['b2'] = dw2 + self.reg*W2, db2\n",
        "        grads['W1'], grads['b1'] = dw1 + self.reg*W1, db1\n",
        "\n",
        "        return loss, grads\n",
        "\n",
        "\n",
        "def conv_forward_naive(x, w, b, conv_param):\n",
        "    \"\"\"\n",
        "    A naive implementation of the forward pass for a convolutional layer.\n",
        "\n",
        "    The input consists of N data points, each with C channels, height H and\n",
        "    width W. We convolve each input with F different filters, where each filter\n",
        "    spans all C channels and has height HH and width HH.\n",
        "\n",
        "    Input:\n",
        "    - x: Input data of shape (N, C, H, W)\n",
        "    - w: Filter weights of shape (F, C, HH, WW)\n",
        "    - b: Biases, of shape (F,)\n",
        "    - conv_param: A dictionary with the following keys:\n",
        "      - 'stride': The number of pixels between adjacent receptive fields in the\n",
        "        horizontal and vertical directions.\n",
        "      - 'pad': The number of pixels that will be used to zero-pad the input.\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: Output data, of shape (N, F, H', W') where H' and W' are given by\n",
        "      H' = 1 + (H + 2 * pad - HH) / stride\n",
        "      W' = 1 + (W + 2 * pad - WW) / stride\n",
        "    - cache: (x, w, b, conv_param)\n",
        "    \"\"\"\n",
        "    out = None\n",
        "\n",
        "    pad = conv_param.get('pad')\n",
        "    stride = conv_param.get('stride')\n",
        "    N, C, H, W = x.shape\n",
        "    F, C, HH, WW = w.shape\n",
        "\n",
        "    # redefine the output shape based on stride number\n",
        "    out_H = np.int(((H + 2 * pad - HH) / stride) + 1)# Define it\n",
        "    out_W = np.int(((W + 2 * pad - WW) / stride) + 1)# Define it\n",
        "    out = np.zeros([N, F, out_H, out_W])\n",
        "    \n",
        "    # add zeros around the original image to match input and output size\n",
        "    padded_x = (np.pad(x, ((0, 0), (0, 0), (pad, pad), (pad, pad)), 'constant'))\n",
        "\n",
        "    for n in range(N): \n",
        "        for f in range(F): \n",
        "            for j in range(out_H):\n",
        "                for i in range(out_W): \n",
        "                    out[n, f, j, i] = np.sum(w[f, ...] * padded_x[n, :, j*stride:j*stride+HH, i*stride:i*stride+WW]) + b[f]\n",
        "                    \n",
        "                    \n",
        "\n",
        "                                        \n",
        "    ###########################################################################\n",
        "    # TODO: Implement the convolutional forward pass.                         #\n",
        "    # Hint: you can use the function np.pad for padding.                      #\n",
        "    ###########################################################################\n",
        "                        \n",
        "    cache = (x, w, b, conv_param)\n",
        "    return out, cache\n",
        "\n",
        "\n",
        "def conv_backward_naive(dout, cache):\n",
        "    \"\"\"\n",
        "    A naive implementation of the backward pass for a convolutional layer.\n",
        "\n",
        "    Inputs:\n",
        "    - dout: Upstream derivatives.\n",
        "    - cache: A tuple of (x, w, b, conv_param) as in conv_forward_naive\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dx: Gradient with respect to x\n",
        "    - dw: Gradient with respect to w\n",
        "    - db: Gradient with respect to b\n",
        "    \"\"\"\n",
        "    dx, dw, db = None, None, None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the convolutional backward pass.                        #\n",
        "    ###########################################################################\n",
        "    \n",
        "    x, w, b, conv_param = cache\n",
        "    stride = conv_param.get('stride')\n",
        "    pad = conv_param.get('pad')\n",
        "    padded_x = (np.pad(x, ((0, 0), (0, 0), (pad, pad), (pad, pad)), 'constant'))\n",
        "\n",
        "    N, C, H, W = x.shape\n",
        "    F, C, HH, WW = w.shape\n",
        "    N, F, H_out, W_out = dout.shape\n",
        "\n",
        "    dx_temp = np.zeros_like(padded_x)\n",
        "    dw = np.zeros_like(w)\n",
        "    db = np.zeros_like(b)\n",
        "\n",
        "\n",
        "    \n",
        "    # Calculate dB.\n",
        "    for f in range(F): \n",
        "        db[f] += np.sum(dout[:, f, :, :])\n",
        "    # Calculate dw.\n",
        "    for n in range(N): # n th image\n",
        "        for f in range(F): # f th filter \n",
        "            for j in range(H_out): # the jth column position of fth filter\n",
        "                for i in range(W_out): # the ith row position of fth filter\n",
        "                    dw[f, ...] += dout[n, f, j, i] * \\\n",
        "                    padded_x[n,:,j*stride:j*stride+HH,i*stride:i*stride+WW]\n",
        "    # Calculate dx.\n",
        "    for n in range(N): \n",
        "        for f in range(F):\n",
        "            for j in range(H_out):\n",
        "                for i in range(W_out):\n",
        "                    dx_temp[n, :, j*stride:j*stride+HH,i*stride:i*stride+WW] \\\n",
        "                    += dout[n, f, j,i] * w[f, ...]\n",
        "                    \n",
        "                    \n",
        "    dx = dx_temp[:, :, pad:H+pad, pad:W+pad]\n",
        "    return dx, dw, db\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BRyiGqp9-3Uh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d129806e-8254-444b-cab2-cbf3c5c1ec4f"
      },
      "cell_type": "code",
      "source": [
        "# Load the (preprocessed) CIFAR10 data.\n",
        "\n",
        "data = get_CIFAR10_data()\n",
        "for k, v in data.items():\n",
        "  print('%s: ' % k, v.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_val:  (1000, 3, 32, 32)\n",
            "X_train:  (49000, 3, 32, 32)\n",
            "X_test:  (1000, 3, 32, 32)\n",
            "y_val:  (1000,)\n",
            "y_train:  (49000,)\n",
            "y_test:  (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WO2r9nOa-3Uq"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolution: Naive forward pass\n",
        "The core of a convolutional network is the convolution operation. In the file `stats232a/layers.py`, implement the forward pass for the convolution layer in the function `conv_forward_naive`. \n",
        "\n",
        "You don't have to worry too much about efficiency at this point; just write the code in whatever way you find most clear.\n",
        "\n",
        "You can test your implementation by running the following:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IDXKQokg-3Ut",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eff9edd6-39a1-4e73-a437-75f4b23a8878"
      },
      "cell_type": "code",
      "source": [
        "x_shape = (2, 3, 4, 4)\n",
        "w_shape = (3, 3, 4, 4)\n",
        "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
        "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
        "b = np.linspace(-0.1, 0.2, num=3)\n",
        "\n",
        "conv_param = {'stride': 2, 'pad': 1}\n",
        "out, _ = conv_forward_naive(x, w, b, conv_param)\n",
        "correct_out = np.array([[[[-0.08759809, -0.10987781],\n",
        "                           [-0.18387192, -0.2109216 ]],\n",
        "                          [[ 0.21027089,  0.21661097],\n",
        "                           [ 0.22847626,  0.23004637]],\n",
        "                          [[ 0.50813986,  0.54309974],\n",
        "                           [ 0.64082444,  0.67101435]]],\n",
        "                         [[[-0.98053589, -1.03143541],\n",
        "                           [-1.19128892, -1.24695841]],\n",
        "                          [[ 0.69108355,  0.66880383],\n",
        "                           [ 0.59480972,  0.56776003]],\n",
        "                          [[ 2.36270298,  2.36904306],\n",
        "                           [ 2.38090835,  2.38247847]]]])\n",
        "\n",
        "# Compare your output to ours; difference should be around 2e-8\n",
        "print('Testing conv_forward_naive')\n",
        "print('difference: ', rel_error(out, correct_out))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing conv_forward_naive\n",
            "difference:  2.2121476417505994e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VuA0qnU2-3U5"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolution: Naive backward pass\n",
        "Implement the backward pass for the convolution operation in the function `conv_backward_naive` in the file `stats232a/layers.py`. Again, you don't need to worry too much about computational efficiency.\n",
        "\n",
        "When you are done, run the following to check your backward pass with a numeric gradient check."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RzndzpbP-3U6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "485143f3-5c3e-4692-d7a5-b3cbd89d610a"
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(231)\n",
        "x = np.random.randn(4, 3, 5, 5)\n",
        "w = np.random.randn(2, 3, 3, 3)\n",
        "b = np.random.randn(2,)\n",
        "dout = np.random.randn(4, 2, 5, 5)\n",
        "conv_param = {'stride': 1, 'pad': 1}\n",
        "\n",
        "dx_num = eval_numerical_gradient_array(lambda x: conv_forward_naive(x, w, b, conv_param)[0], x, dout)\n",
        "dw_num = eval_numerical_gradient_array(lambda w: conv_forward_naive(x, w, b, conv_param)[0], w, dout)\n",
        "db_num = eval_numerical_gradient_array(lambda b: conv_forward_naive(x, w, b, conv_param)[0], b, dout)\n",
        "\n",
        "out, cache = conv_forward_naive(x, w, b, conv_param)\n",
        "dx, dw, db = conv_backward_naive(dout, cache)\n",
        "\n",
        "# Your errors should be around 1e-8'\n",
        "print('Testing conv_backward_naive function')\n",
        "print('dx error: ', rel_error(dx, dx_num))\n",
        "print('dw error: ', rel_error(dw, dw_num))\n",
        "print('db error: ', rel_error(db, db_num))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing conv_backward_naive function\n",
            "dx error:  1.159803161159293e-08\n",
            "dw error:  2.2471264748452487e-10\n",
            "db error:  3.3726153958780465e-11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sI8YpUhP-3W5"
      },
      "cell_type": "markdown",
      "source": [
        "# Fast layers\n",
        "Making convolution and pooling layers fast can be challenging. To spare you the pain, we've provided fast implementations of the forward and backward passes for convolution and pooling layers in the file `stats232a/fast_layers.py`.\n",
        "\n",
        "The fast convolution implementation depends on a Cython extension; to compile it you need to run the following from the `stats232a` directory:\n",
        "\n",
        "```bash\n",
        "python setup.py build_ext --inplace\n",
        "```\n",
        "\n",
        "The API for the fast versions of the convolution and pooling layers is exactly the same as the naive versions that you implemented above: the forward pass receives data, weights, and parameters and produces outputs and a cache object; the backward pass recieves upstream derivatives and the cache object and produces gradients with respect to the data and weights.\n",
        "\n",
        "**NOTE:** The fast implementation for pooling will only perform optimally if the pooling regions are non-overlapping and tile the input. If these conditions are not met then the fast pooling implementation will not be much faster than the naive implementation.\n",
        "\n",
        "You can compare the performance of the naive and fast versions of these layers by running the following:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RdXYpdis-3W8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "2b381c92-5aec-4bf5-806f-4b29f5ec5e46"
      },
      "cell_type": "code",
      "source": [
        "from HW5_code.fast_layers import conv_forward_fast, conv_backward_fast\n",
        "from time import time\n",
        "np.random.seed(231)\n",
        "x = np.random.randn(100, 3, 31, 31)\n",
        "w = np.random.randn(25, 3, 3, 3)\n",
        "b = np.random.randn(25,)\n",
        "dout = np.random.randn(100, 25, 16, 16)\n",
        "conv_param = {'stride': 2, 'pad': 1}\n",
        "\n",
        "t0 = time()\n",
        "out_naive, cache_naive = conv_forward_naive(x, w, b, conv_param)\n",
        "t1 = time()\n",
        "out_fast, cache_fast = conv_forward_fast(x, w, b, conv_param)\n",
        "t2 = time()\n",
        "\n",
        "print('Testing conv_forward_fast:')\n",
        "print('Naive: %fs' % (t1 - t0))\n",
        "print('Fast: %fs' % (t2 - t1))\n",
        "print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
        "print('Difference: ', rel_error(out_naive, out_fast))\n",
        "\n",
        "t0 = time()\n",
        "dx_naive, dw_naive, db_naive = conv_backward_naive(dout, cache_naive)\n",
        "t1 = time()\n",
        "dx_fast, dw_fast, db_fast = conv_backward_fast(dout, cache_fast)\n",
        "t2 = time()\n",
        "\n",
        "print('\\nTesting conv_backward_fast:')\n",
        "print('Naive: %fs' % (t1 - t0))\n",
        "print('Fast: %fs' % (t2 - t1))\n",
        "print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
        "print('dx difference: ', rel_error(dx_naive, dx_fast))\n",
        "print('dw difference: ', rel_error(dw_naive, dw_fast))\n",
        "print('db difference: ', rel_error(db_naive, db_fast))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing conv_forward_fast:\n",
            "Naive: 5.567968s\n",
            "Fast: 0.017584s\n",
            "Speedup: 316.648136x\n",
            "Difference:  4.926407851494105e-11\n",
            "\n",
            "Testing conv_backward_fast:\n",
            "Naive: 9.390247s\n",
            "Fast: 0.014021s\n",
            "Speedup: 669.731176x\n",
            "dx difference:  1.949764775345631e-11\n",
            "dw difference:  3.681156828004736e-13\n",
            "db difference:  3.1393858025571252e-15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cRRLDOYH-3XA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "919243dd-b78d-4d33-db5b-9145b30d3638"
      },
      "cell_type": "code",
      "source": [
        "from HW5_code.fast_layers import max_pool_forward_fast, max_pool_backward_fast\n",
        "np.random.seed(231)\n",
        "x = np.random.randn(100, 3, 32, 32)\n",
        "dout = np.random.randn(100, 3, 16, 16)\n",
        "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
        "\n",
        "t0 = time()\n",
        "out_naive, cache_naive = max_pool_forward_naive(x, pool_param)\n",
        "t1 = time()\n",
        "out_fast, cache_fast = max_pool_forward_fast(x, pool_param)\n",
        "t2 = time()\n",
        "\n",
        "print('Testing pool_forward_fast:')\n",
        "print('Naive: %fs' % (t1 - t0))\n",
        "print('fast: %fs' % (t2 - t1))\n",
        "print('speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
        "print('difference: ', rel_error(out_naive, out_fast))\n",
        "\n",
        "t0 = time()\n",
        "dx_naive = max_pool_backward_naive(dout, cache_naive)\n",
        "t1 = time()\n",
        "dx_fast = max_pool_backward_fast(dout, cache_fast)\n",
        "t2 = time()\n",
        "\n",
        "print('\\nTesting pool_backward_fast:')\n",
        "print('Naive: %fs' % (t1 - t0))\n",
        "print('speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
        "print('dx difference: ', rel_error(dx_naive, dx_fast))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing pool_forward_fast:\n",
            "Naive: 0.406031s\n",
            "fast: 0.002661s\n",
            "speedup: 152.586417x\n",
            "difference:  0.0\n",
            "\n",
            "Testing pool_backward_fast:\n",
            "Naive: 0.512846s\n",
            "speedup: 39.205924x\n",
            "dx difference:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ILANeX-z-3Xv"
      },
      "cell_type": "markdown",
      "source": [
        "# Three-layer ConvNet\n",
        "Now that you have implemented all the necessary layers, we can put them together into a simple convolutional network.\n",
        "\n",
        "Open the file `stats232a/classifiers/cnn.py` and complete the implementation of the `ThreeLayerConvNet` class. Run the following cells to help you debug:"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "itHSETJ2-3Xw"
      },
      "cell_type": "markdown",
      "source": [
        "## Sanity check loss\n",
        "After you build a new network, one of the first things you should do is sanity check the loss. When we use the softmax loss, we expect the loss for random weights (and no regularization) to be about `log(C)` for `C` classes. When we add regularization this should go up."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kv0O3yoA-3Xy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0975c63e-607f-40e5-c609-8d23da5b070d"
      },
      "cell_type": "code",
      "source": [
        "model = ThreeLayerConvNet()\n",
        "\n",
        "N = 50\n",
        "X = np.random.randn(N, 3, 32, 32)\n",
        "y = np.random.randint(10, size=N)\n",
        "\n",
        "loss, grads = model.loss(X, y)\n",
        "print('Initial loss (no regularization): ', loss)\n",
        "\n",
        "model.reg = 0.5\n",
        "loss, grads = model.loss(X, y)\n",
        "print('Initial loss (with regularization): ', loss)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial loss (no regularization):  2.3025858848360223\n",
            "Initial loss (with regularization):  2.508810654189889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "V1_xvb7b-3YG"
      },
      "cell_type": "markdown",
      "source": [
        "## Gradient check\n",
        "After the loss looks reasonable, use numeric gradient checking to make sure that your backward pass is correct. When you use numeric gradient checking you should use a small amount of artifical data and a small number of neurons at each layer. Note: correct implementations may still have relative errors up to 1e-2."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZBFCiUq1-3YJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9a4d479d-806b-431f-f388-041d39802519"
      },
      "cell_type": "code",
      "source": [
        "num_inputs = 2\n",
        "input_dim = (3, 16, 16)\n",
        "reg = 0.0\n",
        "num_classes = 10\n",
        "np.random.seed(231)\n",
        "X = np.random.randn(num_inputs, *input_dim)\n",
        "y = np.random.randint(num_classes, size=num_inputs)\n",
        "\n",
        "model = ThreeLayerConvNet(num_filters=3, filter_size=3,\n",
        "                          input_dim=input_dim, hidden_dim=7,\n",
        "                          dtype=np.float64)\n",
        "loss, grads = model.loss(X, y)\n",
        "for param_name in sorted(grads):\n",
        "    f = lambda _: model.loss(X, y)[0]\n",
        "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-6)\n",
        "    e = rel_error(param_grad_num, grads[param_name])\n",
        "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1 max relative error: 1.380104e-04\n",
            "W2 max relative error: 1.822723e-02\n",
            "W3 max relative error: 3.064049e-04\n",
            "b1 max relative error: 3.477652e-05\n",
            "b2 max relative error: 2.516375e-03\n",
            "b3 max relative error: 7.945660e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3KVdehwr-3YS"
      },
      "cell_type": "markdown",
      "source": [
        "## Overfit small data\n",
        "A nice trick is to train your model with just a few training samples. You should be able to overfit small datasets, which will result in very high training accuracy and comparatively low validation accuracy."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vrToXqrv-3YT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "ee8f3001-92db-4992-8793-13ac233fb02c"
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(6666666)\n",
        "\n",
        "num_train = 100\n",
        "small_data = {\n",
        "  'X_train': data['X_train'][:num_train],\n",
        "  'y_train': data['y_train'][:num_train],\n",
        "  'X_val': data['X_val'],\n",
        "  'y_val': data['y_val'],\n",
        "}\n",
        "\n",
        "model = ThreeLayerConvNet(weight_scale=1e-2)\n",
        "\n",
        "solver = Solver(model, small_data,\n",
        "                num_epochs=15, batch_size=50,\n",
        "                update_rule='adam',\n",
        "                optim_config={\n",
        "                  'learning_rate': 1e-3,\n",
        "                },\n",
        "                verbose=True, print_every=1)\n",
        "solver.train()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Epoch 0 / 15, iteration 1 / 30) train acc: 0.170000; val_acc: 0.119000\n",
            "(Epoch 1 / 15, iteration 2 / 30) train acc: 0.180000; val_acc: 0.119000\n",
            "(Epoch 1 / 15, iteration 3 / 30) train acc: 0.250000; val_acc: 0.134000\n",
            "(Epoch 2 / 15, iteration 4 / 30) train acc: 0.260000; val_acc: 0.121000\n",
            "(Epoch 2 / 15, iteration 5 / 30) train acc: 0.210000; val_acc: 0.109000\n",
            "(Epoch 3 / 15, iteration 6 / 30) train acc: 0.400000; val_acc: 0.128000\n",
            "(Epoch 3 / 15, iteration 7 / 30) train acc: 0.400000; val_acc: 0.119000\n",
            "(Epoch 4 / 15, iteration 8 / 30) train acc: 0.400000; val_acc: 0.150000\n",
            "(Epoch 4 / 15, iteration 9 / 30) train acc: 0.360000; val_acc: 0.164000\n",
            "(Epoch 5 / 15, iteration 10 / 30) train acc: 0.380000; val_acc: 0.150000\n",
            "(Epoch 5 / 15, iteration 11 / 30) train acc: 0.380000; val_acc: 0.112000\n",
            "(Epoch 6 / 15, iteration 12 / 30) train acc: 0.420000; val_acc: 0.127000\n",
            "(Epoch 6 / 15, iteration 13 / 30) train acc: 0.560000; val_acc: 0.164000\n",
            "(Epoch 7 / 15, iteration 14 / 30) train acc: 0.580000; val_acc: 0.187000\n",
            "(Epoch 7 / 15, iteration 15 / 30) train acc: 0.620000; val_acc: 0.196000\n",
            "(Epoch 8 / 15, iteration 16 / 30) train acc: 0.610000; val_acc: 0.194000\n",
            "(Epoch 8 / 15, iteration 17 / 30) train acc: 0.690000; val_acc: 0.197000\n",
            "(Epoch 9 / 15, iteration 18 / 30) train acc: 0.710000; val_acc: 0.185000\n",
            "(Epoch 9 / 15, iteration 19 / 30) train acc: 0.690000; val_acc: 0.172000\n",
            "(Epoch 10 / 15, iteration 20 / 30) train acc: 0.710000; val_acc: 0.181000\n",
            "(Epoch 10 / 15, iteration 21 / 30) train acc: 0.770000; val_acc: 0.188000\n",
            "(Epoch 11 / 15, iteration 22 / 30) train acc: 0.720000; val_acc: 0.191000\n",
            "(Epoch 11 / 15, iteration 23 / 30) train acc: 0.720000; val_acc: 0.200000\n",
            "(Epoch 12 / 15, iteration 24 / 30) train acc: 0.760000; val_acc: 0.197000\n",
            "(Epoch 12 / 15, iteration 25 / 30) train acc: 0.800000; val_acc: 0.184000\n",
            "(Epoch 13 / 15, iteration 26 / 30) train acc: 0.800000; val_acc: 0.180000\n",
            "(Epoch 13 / 15, iteration 27 / 30) train acc: 0.850000; val_acc: 0.183000\n",
            "(Epoch 14 / 15, iteration 28 / 30) train acc: 0.900000; val_acc: 0.194000\n",
            "(Epoch 14 / 15, iteration 29 / 30) train acc: 0.920000; val_acc: 0.203000\n",
            "(Epoch 15 / 15, iteration 30 / 30) train acc: 0.950000; val_acc: 0.208000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ecoSFk2y-3YZ"
      },
      "cell_type": "markdown",
      "source": [
        "Plotting the loss, training accuracy, and validation accuracy should show clear overfitting:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "r8WyU2tJ-3Yb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "caf79f79-e884-4bb9-93e8-7a8edbb797bd"
      },
      "cell_type": "code",
      "source": [
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(solver.loss_history, 'o')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(solver.train_acc_history, '-o')\n",
        "plt.plot(solver.val_acc_history, '-o')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAHgCAYAAACbywggAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYQQQpSQBF9CCCGEECX0/wGMC4cQeTRpKgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4a0cff9ad0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "RxC48Xkv-3Yg"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the net\n",
        "By training the three-layer convolutional network for one epoch, you should achieve greater than 40% accuracy on the training set:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VAhfjmNS-3Yi",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "367223cb-433f-4607-a2ed-9c68013e5b35"
      },
      "cell_type": "code",
      "source": [
        "model = ThreeLayerConvNet(reg=0.001)\n",
        "\n",
        "# Try to change update_rule : 'sgd' / 'sgd_momentum' / 'rmsprop' / 'adam'\n",
        "# Then try learning rate and reg.\n",
        "\n",
        "solver = Solver(model, data,\n",
        "                num_epochs=1, batch_size=200,\n",
        "                update_rule='adam',\n",
        "                optim_config={\n",
        "                  'learning_rate': 0.001,\n",
        "                },\n",
        "                verbose=True, print_every=20)\n",
        "solver.train()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Epoch 0 / 1, iteration 1 / 245) train acc: 0.096000; val_acc: 0.098000\n",
            "(Epoch 0 / 1, iteration 21 / 245) train acc: 0.292000; val_acc: 0.327000\n",
            "(Epoch 0 / 1, iteration 41 / 245) train acc: 0.411000; val_acc: 0.395000\n",
            "(Epoch 0 / 1, iteration 61 / 245) train acc: 0.406000; val_acc: 0.423000\n",
            "(Epoch 0 / 1, iteration 81 / 245) train acc: 0.435000; val_acc: 0.451000\n",
            "(Epoch 0 / 1, iteration 101 / 245) train acc: 0.461000; val_acc: 0.453000\n",
            "(Epoch 0 / 1, iteration 121 / 245) train acc: 0.457000; val_acc: 0.484000\n",
            "(Epoch 0 / 1, iteration 141 / 245) train acc: 0.477000; val_acc: 0.490000\n",
            "(Epoch 0 / 1, iteration 161 / 245) train acc: 0.508000; val_acc: 0.493000\n",
            "(Epoch 0 / 1, iteration 181 / 245) train acc: 0.477000; val_acc: 0.488000\n",
            "(Epoch 0 / 1, iteration 201 / 245) train acc: 0.495000; val_acc: 0.511000\n",
            "(Epoch 0 / 1, iteration 221 / 245) train acc: 0.501000; val_acc: 0.512000\n",
            "(Epoch 0 / 1, iteration 241 / 245) train acc: 0.513000; val_acc: 0.523000\n",
            "(Epoch 1 / 1, iteration 245 / 245) train acc: 0.489000; val_acc: 0.515000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "21RGsBxx-3Y3"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualize Filters\n",
        "You can visualize the first-layer convolutional filters from the trained network by running the following:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ldg8_urL-3Y5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "6d026277-048e-4eae-9b2c-10a70ab51ba9"
      },
      "cell_type": "code",
      "source": [
        "from HW5_code.vis_utils import visualize_grid\n",
        "\n",
        "grid = visualize_grid(model.params['W1'].transpose(0, 2, 3, 1))\n",
        "plt.imshow(grid.astype('uint8'))\n",
        "plt.axis('off')\n",
        "plt.gcf().set_size_inches(5, 5)\n",
        "plt.show()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATAAAAEwCAYAAAAw+y3zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4a1081dd90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "yJayvx9cwJGm"
      },
      "cell_type": "markdown",
      "source": [
        "##Extra Credit\n",
        "\n",
        "Try to more interesting observation as you wish! "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_FdmobjVwIqc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "625f04b6-f260-455b-e44f-56cef280c20b"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ne3oADJFyyQR"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright: This tamplate is original from Stanford cs231n opensource online course. Modification is made by Ruiqi Gao and Yifei Xu. No distribution is permitted."
      ]
    }
  ]
}