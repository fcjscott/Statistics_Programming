{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "## Stat 202A - Homework 6 SVM & Adaboost\n",
    "## Author: Chaojie Feng\n",
    "## Date : Nov.25, 2018\n",
    "## Description: This script implements a support vector machine, an adaboost classifier\n",
    "#########################################################\n",
    "\n",
    "#############################################################\n",
    "## INSTRUCTIONS: Please fill in the missing lines of code\n",
    "## only where specified. Do not change function names,\n",
    "## function inputs or outputs. You can add examples at the\n",
    "## end of the script (in the \"Optional examples\" section) to\n",
    "## double-check your work, but MAKE SURE TO COMMENT OUT ALL\n",
    "## OF YOUR EXAMPLES BEFORE SUBMITTING.\n",
    "##\n",
    "## Very important: Do not use the function \"os.chdir\" anywhere\n",
    "## in your code. If you do, I will be unable to grade your\n",
    "## work since Python will attempt to change my working directory\n",
    "## to one that does not exist.\n",
    "#############################################################\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def prepare_data(valid_digits=np.array((6, 5))):\n",
    "    ## valid_digits is a vector containing the digits\n",
    "    ## we wish to classify.\n",
    "    ## Do not change anything inside of this function\n",
    "    if len(valid_digits) != 2:\n",
    "        raise Exception(\n",
    "            \"Error: you must specify exactly 2 digits for classification!\")\n",
    "\n",
    "    data = ds.load_digits()\n",
    "    labels = data['target']\n",
    "    features = data['data']\n",
    "    X = features[(labels == valid_digits[0]) | (labels == valid_digits[1]), :]\n",
    "    Y = labels[(labels == valid_digits[0]) | (labels == valid_digits[1]), ]\n",
    "    X = X / np.repeat(np.max(X, axis=1), 64).reshape(X.shape[0], -1)\n",
    "\n",
    "    Y[Y == valid_digits[0]] = 0\n",
    "    Y[Y == valid_digits[1]] = 1\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.25, random_state=10)\n",
    "    Y_train = Y_train.reshape((len(Y_train), 1))\n",
    "    Y_test = Y_test.reshape((len(Y_test), 1))\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "####################################################\n",
    "##           1: Support vector machine            ##\n",
    "####################################################\n",
    "\n",
    "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##\n",
    "## Train an SVM to classify the digits data ##\n",
    "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##\n",
    "\n",
    "def my_SVM(X_train, Y_train, X_test, Y_test, lamb=0.01, num_iterations=400, learning_rate=0.1):\n",
    "    ## X_train: Training set of features\n",
    "    ## Y_train: Training set of labels corresponding to X_train\n",
    "    ## X_test: Testing set of features\n",
    "    ## Y_test: Testing set of labels correspdonding to X_test\n",
    "    ## lamb: Regularization parameter\n",
    "    ## num_iterations: Number of iterations.\n",
    "    ## learning_rate: Learning rate.\n",
    "\n",
    "    ## Function should learn the parameters of an SVM.\n",
    "    ## Intercept term is needed.\n",
    "\n",
    "    #######################\n",
    "    ## FILL IN CODE HERE ##\n",
    "    #######################\n",
    "    n,p = X_train.shape\n",
    "    X1 = np.column_stack((np.ones(n),X_train))\n",
    "    print(X1.shape)\n",
    "    Y_train = 2*Y_train - 1\n",
    "    Y_test = 2*Y_test - 1\n",
    "    beta = np.random.rand((p+1),1)\n",
    "    print(beta.shape)\n",
    "    acc_train = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        s = X1.dot(beta)\n",
    "        de = s * (Y_train < 1)\n",
    "        dbeta = X1.T.dot(de * Y_train)/n\n",
    "        dbeta[1:] = dbeta[1:] + lamb*beta[1:]\n",
    "        beta = beta + learning_rate*dbeta  \n",
    "        \n",
    "        y_train_pred = X1.dot(beta)\n",
    "        acc_train.append(sum((np.sign(y_train_pred) - Y_train)==0)/n)\n",
    "    \n",
    "    acc_test = 0\n",
    "    acc_test = 0\n",
    "\n",
    "    ## Function should output 3 things:\n",
    "    ## 1. The learned parameters of the SVM, beta\n",
    "    ## 2. The accuracy over the training set, acc_train (a \"num_iterations\" dimensional vector).\n",
    "    ## 3. The accuracy over the testing set, acc_test (a \"num_iterations\" dimensional vector).\n",
    "\n",
    "    return beta, acc_train, acc_test\n",
    "\n",
    "######################################\n",
    "## Function 2: Adaboost ##\n",
    "######################################\n",
    "\n",
    "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##\n",
    "## Use Adaboost to classify the digits data ##\n",
    "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##\n",
    "\n",
    "\n",
    "def my_Adaboost(X_train, Y_train, X_test, Y_test, num_iterations=200):\n",
    "    ## X_train: Training set of features\n",
    "    ## Y_train: Training set of labels corresponding to X_train\n",
    "    ## X_test: Testing set of features\n",
    "    ## Y_test: Testing set of labels correspdonding to X_test\n",
    "    ## num_iterations: Number of iterations.\n",
    "\n",
    "    ## Function should learn the parameters of an Adaboost classifier.\n",
    "    ## Intercept term is needed.\n",
    "\n",
    "    #######################\n",
    "    ## FILL IN CODE HERE ##\n",
    "    #######################\n",
    "\n",
    "    ## Function should output 3 things:\n",
    "    ## 1. The learned parameters of the adaboost classifier, beta\n",
    "    ## 2. The accuracy over the training set, acc_train (a \"num_iterations\" dimensional vector).\n",
    "    ## 3. The accuracy over the testing set, acc_test (a \"num_iterations\" dimensional vector).\n",
    "    return beta, acc_train, acc_test\n",
    "\n",
    "############################################################################\n",
    "## Testing your functions and visualize the results here##\n",
    "############################################################################\n",
    "\n",
    "\n",
    "def testing_example():\n",
    "\n",
    "    ####################################################\n",
    "    ## Optional examples (comment out your examples!) ##\n",
    "    ####################################################\n",
    "\n",
    "    X_train, Y_train, X_test, Y_test = prepare_data()\n",
    "\n",
    "    beta, acc_train, acc_test = my_SVM(X_train, Y_train, X_test, Y_test)\n",
    "    \n",
    "    print(acc_train)\n",
    "\n",
    "    ax = plt.plot(range(200), acc_train, range(200), acc_test)\n",
    "    plt.xlabel('Number of iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(('Training Accuracy', 'Testing Accuracy'))\n",
    "    plt.show()\n",
    "\n",
    "    beta, acc_train, acc_test = my_Adaboost(X_train, Y_train, X_test, Y_test)\n",
    "    plt.plot(range(200), acc_train, range(200), acc_test)\n",
    "    plt.xlabel('Number of iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(('Training Accuracy', 'Testing Accuracy'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 65)\n",
      "(65, 1)\n",
      "[array([0.53308824]), array([0.53308824]), array([0.61397059]), array([0.71691176]), array([0.76102941]), array([0.76838235]), array([0.77941176]), array([0.78308824]), array([0.78308824]), array([0.78308824]), array([0.77941176]), array([0.77573529]), array([0.77205882]), array([0.77573529]), array([0.77573529]), array([0.76838235]), array([0.76838235]), array([0.76838235]), array([0.77205882]), array([0.76838235]), array([0.76838235]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76838235]), array([0.76838235]), array([0.77205882]), array([0.77205882]), array([0.77205882]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76102941]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76470588]), array([0.76838235]), array([0.76838235]), array([0.76838235]), array([0.77205882]), array([0.76838235]), array([0.76470588]), array([0.76102941]), array([0.76102941]), array([0.76102941]), array([0.75735294]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75367647]), array([0.75367647]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.74632353]), array([0.74632353]), array([0.74632353]), array([0.75]), array([0.75]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75735294]), array([0.75735294]), array([0.75735294]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75735294]), array([0.75735294]), array([0.75735294]), array([0.75735294]), array([0.75735294]), array([0.75735294]), array([0.75735294]), array([0.75735294]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75367647]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.75]), array([0.74632353]), array([0.74632353]), array([0.74632353]), array([0.74264706]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.74264706]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73897059]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73161765]), array([0.73161765]), array([0.73161765]), array([0.73161765]), array([0.73161765]), array([0.73161765]), array([0.73161765]), array([0.73161765]), array([0.73161765]), array([0.73161765]), array([0.73161765]), array([0.73161765]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73529412]), array([0.73161765]), array([0.73161765]), array([0.73161765])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (200,) and (400, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-3f17dd4f804c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtesting_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-125-0cffed5c5b34>\u001b[0m in \u001b[0;36mtesting_example\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2747\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2748\u001b[0m     return gca().plot(\n\u001b[0;32m-> 2749\u001b[0;31m         *args, scalex=scalex, scaley=scaley, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   2750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2751\u001b[0m \u001b[0;31m# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1783\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1785\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (200,) and (400, 1)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
