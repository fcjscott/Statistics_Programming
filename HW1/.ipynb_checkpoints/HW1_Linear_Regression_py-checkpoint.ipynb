{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    " Stat 202A 2018 Fall - Homework 1-1\n",
    " Author: Chaojie Feng\n",
    " Date : Oct.9,2018\n",
    "\n",
    " Description: This script implements linear regression \n",
    " using Gauss-Jordan elimination in both plain and\n",
    " vectorized forms\n",
    "\n",
    " INSTRUCTIONS: Please fill in the missing lines of code\n",
    " only where specified. Do not change function names, \n",
    " function inputs or outputs. You can add examples at the\n",
    " end of the script (in the \"Optional examples\" section) to \n",
    " double-check your work, but MAKE SURE TO COMMENT OUT ALL \n",
    " OF YOUR EXAMPLES BEFORE SUBMITTING.\n",
    "\n",
    " Do not use any of Python's built in functions for matrix \n",
    " inversion or for linear modeling (except for debugging or \n",
    " in the optional examples section).\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "###############################################\n",
    "## Function 1: Plain version of Gauss Jordan ##\n",
    "###############################################\n",
    "\n",
    "def GaussJordan(A, m):\n",
    "    A = A.astype(float)\n",
    "    n = np.shape(A)[0];\n",
    "    B = np.block([A,np.diag(np.repeat(1,n))]);\n",
    "    for k in range(m):\n",
    "        B[k,] = B[k,]/B[k,k]\n",
    "        for i in range(n):\n",
    "            if i != k:\n",
    "                B[i,] = B[i,] - B[k,]*B[i,k];\n",
    "                \n",
    "        \n",
    "  ## Function returns the np.array B\n",
    "    return(B);\n",
    "  \n",
    "####################################################\n",
    "## Function 2: Vectorized version of Gauss Jordan ##\n",
    "####################################################\n",
    "\n",
    "def GaussJordanVec(A, m):\n",
    "  \n",
    "    A = A.astype(float)\n",
    "    n = np.shape(A)[0];\n",
    "    B = np.block([A,np.diag(np.repeat(1,n))]);\n",
    "    for k in range(m):\n",
    "        B[k,] = B[k,]/B[k,k]\n",
    "        for i in range(n):\n",
    "            if i != k:\n",
    "                B[i,] = B[i,] - B[k,]*B[i,k];\n",
    "                \n",
    "        \n",
    "  ## Function returns the np.array B\n",
    "    return(B);\n",
    "  \n",
    "\n",
    "######################################################\n",
    "## Function 3: Linear regression using Gauss Jordan ##\n",
    "######################################################\n",
    "\n",
    "def LinearRegression(X, Y):\n",
    "  \n",
    "    n = np.shape(X)[0]\n",
    "    p = np.shape(X)[1]\n",
    "    X = np.block([np.ones((n,1)),X])\n",
    "    Z = np.block([X,Y])\n",
    "    A = np.matmul(np.transpose(Z),Z)\n",
    "    B = GaussJordan(A,(p+1))\n",
    "    beta_hat = B[0:p+1,p+1]\n",
    "    rss = B[(p+1),(p+1)]\n",
    "    v = B[0:(p+1),(p+2):(p+3+p)]\n",
    "    sigma_2 = rss/(n-p-1)\n",
    "    sigma = np.sqrt(sigma_2)\n",
    "    error = v*sigma_2\n",
    "    \n",
    "    \n",
    "  ## Function returns the (p+1)-dimensional vector \n",
    "  ## beta_hat of regression coefficient estimates\n",
    "    return([beta_hat,sigma_2,error])\n",
    "\n",
    "  \n",
    "########################################################\n",
    "## Optional examples (comment out before submitting!) ##\n",
    "########################################################\n",
    "\n",
    "def testing_Linear_Regression():\n",
    "  \n",
    "  # This function is not graded; you can use it to \n",
    "  # test out the 'myLinearRegression' function \n",
    "\n",
    "  # You can set up a similar test function as was \n",
    "  # provided to you in the R file.\n",
    "  #n = 5\n",
    "  #p = 2\n",
    "  #X = np.random.randn(n,p)\n",
    "  #print(X)\n",
    "  #beta = np.arange(1,p+1)\n",
    "  #Y = (np.dot(X,beta) + np.random.randn(n)).reshape(n,1)\n",
    "  #print(Y)\n",
    "  #py_model = linear_model.LinearRegression(fit_intercept = True).fit(X,Y)\n",
    "  #py_intercept = py_model.intercept_\n",
    "  #py_beta = py_model.coef_\n",
    "  #\n",
    "  #print(py_intercept,py_beta)\n",
    "  #\n",
    "  #beta_ls,sigma_2,error = LinearRegression(X,Y)\n",
    "  #print(beta_ls)\n",
    "  #\n",
    "  #return(0)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LinearRegression() missing 2 required positional arguments: 'X' and 'Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-cdb1ac96ff20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mbeta_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: LinearRegression() missing 2 required positional arguments: 'X' and 'Y'"
     ]
    }
   ],
   "source": [
    "A = np.mat([[5,4,6],[4,3,9],[9,6,7]])\n",
    "B = GaussJordan(A,3)\n",
    "X = np.random.rand(5,2)\n",
    "Y = np.random.rand(5,1)\n",
    "print(np.ones((3,1)))\n",
    "[beta_hat,sigma_2,error] = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.3065382  -1.07495831]\n",
      " [-0.84015994  1.83050947]\n",
      " [ 1.70075996 -1.1113706 ]\n",
      " [ 0.54035001  0.32877189]\n",
      " [-0.2176659  -1.12000968]]\n",
      "[[-0.50844868]\n",
      " [ 2.40794895]\n",
      " [-1.11778334]\n",
      " [ 3.02459363]\n",
      " [-1.74621091]]\n",
      "[0.4392425] [[0.80005152 1.85526838]]\n",
      "[0.4392425  0.80005152 1.85526838]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_Linear_Regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
